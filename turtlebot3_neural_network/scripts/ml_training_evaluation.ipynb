{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7662515",
   "metadata": {},
   "source": [
    "# Machine Learning and Data Analysis\n",
    "\n",
    "### Project - Autonomous Driving and Obstacle avoidance using Machine Learning algorithm in ROS\n",
    "\n",
    "### Description of the Project\n",
    "The Turtlebot robot is a popular platform for robotics research and education. With its sensors, cameras, and actuators, it provides a great platform for testing and developing algorithms for robot navigation and control. One of the key challenges in robotics is autonomous driving and obstacle avoidance, which involves navigating in an environment with unknown obstacles and avoiding collisions. This project aims to address this challenge by using machine learning algorithms to train the Turtlebot robot to avoid obstacles.\n",
    "\n",
    "To implement obstacle avoidance, we start by collecting data using the Turtlebot's laser range finder. This sensor measures the distance to obstacles in the environment and provides a 2D scan of the surroundings. We use this data to train various machine learning classifiers such as Random Forest, KNN, MLP, AdaBoost, Logistic Regression, Gradient Boosting, Extra Tree and Decision Trees. These classifiers learn to classify the environment into obstacle and non-obstacle regions based on the laser scan data. Once the classifiers are trained, we use them to implement obstacle avoidance in the Turtlebot robot. This allows the robot to navigate autonomously in an unknown environment, avoiding obstacles in its path. By using machine learning, we can create intelligent robots that can adapt to different environments and tasks, making them more useful and versatile.\n",
    "\n",
    "## Headers\n",
    "Headers that are used in the entire package are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd2ca93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T23:44:33.197082Z",
     "start_time": "2023-03-01T23:44:33.133976Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, accuracy_score, precision_score, classification_report, recall_score, f1_score, multilabel_confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, validation_curve, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa998a3",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This code reads data from a CSV file named \"data.csv\" and replaces all infinite values with 3.5. The data contains 120 features with column names starting with \"x_\" and two additional columns named \"v\" and \"w\".\n",
    "\n",
    "After reading the data, some data cleaning operations are performed. Values of \"v\" and \"w\" columns are modified such that if \"v\" has a value of 0.3, it is replaced with 1 and if \"w\" has a value of 0.3, it is replaced with 1. Conversely, if \"v\" has a value of 0.3, the corresponding \"w\" value is set to 0, and if \"w\" has a value of 0.3, the corresponding \"v\" value is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a936a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T23:44:37.704248Z",
     "start_time": "2023-03-01T23:44:37.161585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n",
      "        x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
      "0  1.590204  1.602161  1.581147  1.600504  1.597914  1.577481  1.593620   \n",
      "1  1.519810  1.546991  1.526143  1.539950  1.532496  1.537885  1.547140   \n",
      "2  1.484817  1.465451  1.465208  1.466603  1.472045  1.488164  1.475176   \n",
      "3  1.406087  1.403883  1.405478  1.396614  1.401159  1.416241  1.417860   \n",
      "4  1.346545  1.342163  1.357281  1.345461  1.356633  1.360663  1.353894   \n",
      "\n",
      "        x_7       x_8       x_9  ...     x_112     x_113     x_114     x_115  \\\n",
      "0  1.613339  1.601755  1.600173  ...  1.610716  1.608843  1.589687  1.604537   \n",
      "1  1.535099  1.533105  1.559243  ...  1.526062  1.533277  1.530861  1.530371   \n",
      "2  1.487901  1.493488  1.491741  ...  1.475144  1.487471  1.499951  1.474804   \n",
      "3  1.417356  1.424088  1.414250  ...  1.422196  1.412065  1.412352  1.407603   \n",
      "4  1.360166  1.375422  1.366590  ...  1.354234  1.346220  1.362369  1.356384   \n",
      "\n",
      "      x_116     x_117     x_118     x_119    v    w  \n",
      "0  1.574301  1.577494  1.589971  1.593945  1.0  0.0  \n",
      "1  1.532303  1.537875  1.521654  1.540356  1.0  0.0  \n",
      "2  1.463833  1.475039  1.462201  1.480577  1.0  0.0  \n",
      "3  1.404215  1.407768  1.391994  1.393131  1.0  0.0  \n",
      "4  1.353866  1.359438  1.357774  1.357863  1.0  0.0  \n",
      "\n",
      "[5 rows x 122 columns]\n",
      "Number of Data Entries: 16604\n",
      "Number of v Entries: 5753\n",
      "Number of w Entries: 10851\n",
      "X shape: (16604, 120)\n",
      "y shape: (16604,)\n",
      "X data types: float64\n",
      "y data types: int64\n",
      "X range: 0.1199999973177909 3.5\n",
      "y range: 0 1\n",
      "Number of missing values in X: 0\n",
      "Number of missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "columns = []\n",
    "for i in range(120):\n",
    "    columns.append(f'x_{i}')\n",
    "\n",
    "columns = columns + ['v', 'w']\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.replace([np.inf], 3.5, inplace=True)\n",
    "\n",
    "df.columns = columns\n",
    "df.loc[df['v'] == 0.3, \"v\"] = 1\n",
    "df.loc[df['v'] == 0.3, \"w\"] = 0\n",
    "df.loc[df['w'] == 0.3, \"v\"] = 0\n",
    "df.loc[df['w'] == 0.3, \"w\"] = 1\n",
    "\n",
    "print(\"Raw Data\")\n",
    "print(df.head(5))\n",
    "print(f\"Number of Data Entries: {len(df)}\")\n",
    "print(f\"Number of v Entries: {len(df[df['v'] == 1])}\")\n",
    "print(f\"Number of w Entries: {len(df[df['w'] == 1])}\")\n",
    "\n",
    "# Split into features and labels\n",
    "X = df.drop(['v', 'w'], axis=1).values # extract features\n",
    "y = df[['v', 'w']].values # extract labels\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "# Verifying the data after preprocessing\n",
    "\n",
    "# Check the shape of X and y\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "# Check the data types of X and y\n",
    "print('X data types:', X.dtype)\n",
    "print('y data types:', y.dtype)\n",
    "\n",
    "# Check the range of values for X and y\n",
    "print('X range:', X.min(), X.max())\n",
    "print('y range:', y.min(), y.max())\n",
    "\n",
    "# Check for missing values in X and y\n",
    "print('Number of missing values in X:', np.isnan(X).sum())\n",
    "print('Number of missing values in y:', np.isnan(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9083d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T23:44:52.626558Z",
     "start_time": "2023-03-01T23:44:52.570442Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc93c9",
   "metadata": {},
   "source": [
    "## Classifiers used in the project\n",
    "The project uses the following classifiers in the code:\n",
    "1. Decision Tree Classifier\n",
    "2. Random Forest Classifier\n",
    "3. K-Nearest Neighbors Classifier\n",
    "4. MLP Classifier\n",
    "5. Logistic Regression Classifier\n",
    "6. Gradient Boosting Classifier\n",
    "7. AdaBoost Classifier\n",
    "8. Extra Tree Classifier\n",
    "\n",
    "\n",
    "\n",
    "# Solving over and underfitting\n",
    "\n",
    "Both overfitting and underfitting should be addressed for the real model that is to be used.\n",
    "\n",
    "Overfitting occurs when the model is too complex and has learned the training data too well, resulting in poor performance on new data. To address overfitting, techniques such as reducing the complexity of the model (e.g., reducing the number of features, decreasing the depth of a decision tree), using regularization (e.g., L1 or L2 regularization), and increasing the amount of training data can be used.\n",
    "\n",
    "Underfitting occurs when the model is too simple and is unable to capture the underlying patterns in the data, resulting in poor performance on both the training and test data. To address underfitting, techniques such as increasing the complexity of the model (e.g., increasing the number of features, increasing the depth of a decision tree), reducing regularization, and using more sophisticated models (e.g., neural networks) can be used.\n",
    "\n",
    "Therefore, it's important to balance the complexity of the model with the amount of training data available and the complexity of the underlying problem to avoid both overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43cac0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T23:46:34.094775Z",
     "start_time": "2023-03-01T23:44:59.839655Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m rf_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: randint(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m     17\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: randint(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m)}\n\u001b[1;32m     18\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(rf_model, rf_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39mn_iter)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m rf_random\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# K-Nearest Neighbors Classifier\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reduce the number of iterations for RandomizedSearchCV\n",
    "n_iter = 10\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_params = {'max_depth': randint(5, 20)}\n",
    "dt_random = RandomizedSearchCV(dt_model, dt_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "dt_random.fit(X_train, y_train)\n",
    "dt_model = dt_random.best_estimator_\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_params = {'n_estimators': randint(100, 500),\n",
    "             'max_depth': randint(5, 20)}\n",
    "rf_random = RandomizedSearchCV(rf_model, rf_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_model = rf_random.best_estimator_\n",
    "\n",
    "# K-Nearest Neighbors Classifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors': randint(1, 21)}\n",
    "knn_random = RandomizedSearchCV(knn_model, knn_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "knn_random.fit(X_train, y_train)\n",
    "knn_model = knn_random.best_estimator_\n",
    "\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 2), activation='relu', solver='adam', max_iter=2000)\n",
    "nn_params = {'hidden_layer_sizes': [(100,), (100, 2), (100, 5)],\n",
    "             'alpha': uniform(0.0001, 0.01)}\n",
    "nn_random = RandomizedSearchCV(nn_model, nn_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "nn_random.fit(X_train, y_train)\n",
    "nn_model = nn_random.best_estimator_\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "lr_model = LogisticRegression(solver='saga', max_iter=2500)\n",
    "lr_params = {'C': randint(1, 10)}\n",
    "lr_rand = RandomizedSearchCV(lr_model, lr_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "lr_rand.fit(X_train, y_train)\n",
    "lr_model = lr_rand.best_estimator_\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_params = {'n_estimators': randint(50, 200),\n",
    "             'max_depth': randint(3, 8)}\n",
    "gb_rand = RandomizedSearchCV(gb_model, gb_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "gb_rand.fit(X_train, y_train)\n",
    "gb_model = gb_rand.best_estimator_\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_params = {'n_estimators': randint(50, 200),\n",
    "              'learning_rate': uniform(0.01, 1)}\n",
    "ada_rand = RandomizedSearchCV(ada_model, ada_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "ada_rand.fit(X_train, y_train)\n",
    "ada_model = ada_rand.best_estimator_\n",
    "\n",
    "# Extra Tree Classifier\n",
    "et_model = ExtraTreesClassifier()\n",
    "et_params = {'n_estimators': randint(100, 500),\n",
    "             'max_depth': randint(5, 20)}\n",
    "et_rand = RandomizedSearchCV(et_model, ada_params, cv=5, n_jobs=-1, n_iter=n_iter)\n",
    "et_rand.fit(X_train,y_train)\n",
    "et_model=et_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create directory if it does not exist\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models as joblib files\n",
    "joblib.dump(dt_model, 'models/dt_model.joblib')\n",
    "joblib.dump(rf_model, 'models/rf_model.joblib')\n",
    "joblib.dump(knn_model, 'models/knn_model.joblib')\n",
    "joblib.dump(nn_model, 'models/nn_model.joblib')\n",
    "joblib.dump(lr_model, 'models/lr_model.joblib')\n",
    "joblib.dump(gb_model, 'models/gb_model.joblib')\n",
    "joblib.dump(ada_model, 'models/ada_model.joblib')\n",
    "joblib.dump(et_model, 'models/et_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [dt_model, rf_model, knn_model, nn_model, lr_model, gb_model, ada_model, et_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d38943",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "This code section defines a function called \"evaluate_model\" that takes in three parameters: a machine learning model, training data (X_train), and target data (y_train). The function uses k-fold cross-validation to evaluate the performance of the machine learning model on the training data. It splits the data into k folds, fits the model on k-1 folds, and evaluates the model on the remaining fold. This process is repeated for each of the k folds. The function returns the mean accuracy, precision, recall, ROC AUC, and F1 scores across all folds, as well as the confusion matrix for each fold. The function can handle both scikit-learn and TensorFlow Keras models, but uses different methods to compute scores and confusion matrices depending on the type of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d44996dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T23:38:39.954433Z",
     "start_time": "2023-02-28T23:38:39.937166Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models_list, X_test, y_test, file_path, print_console = False):\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        \n",
    "        for i, model in enumerate(models_list):\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            y_score = model.predict_proba(X_test)[:, 1]\n",
    "            roc_auc = roc_auc_score(y_test, y_score)\n",
    "            \n",
    "            f.write(f'\\t\\tModel {i+1}: {model.__class__.__name__}\\n')\n",
    "            f.write(f'Accuracy: {accuracy:.4f}\\n')\n",
    "            f.write(f'Precision: {precision:.4f}\\n')\n",
    "            f.write(f'Recall: {recall:.4f}\\n')\n",
    "            f.write(f'F1 score: {f1:.4f}\\n')\n",
    "            f.write(f'ROC AUC score: {roc_auc:.4f}\\n\\n')\n",
    "            \n",
    "            f.write(f'Confusion Matrix:\\n')\n",
    "            f.write(f'{confusion_matrix(y_test, y_pred)}\\n\\n')\n",
    "            \n",
    "            f.write(f'Classification Report:\\n')\n",
    "            f.write(f'{classification_report(y_test, y_pred)}\\n')\n",
    "            f.write('_____________________________________________________________________')\n",
    "            f.write('\\n')\n",
    "            \n",
    "            if(print_console == True):\n",
    "                print(f'\\t\\tModel {i+1}: {model.__class__.__name__}')\n",
    "                print(f'Accuracy: {accuracy:.4f}')\n",
    "                print(f'Precision: {precision:.4f}')\n",
    "                print(f'Recall: {recall:.4f}')\n",
    "                print(f'F1 score: {f1:.4f}')\n",
    "                print(f'ROC AUC score: {roc_auc:.4f}\\n')\n",
    "\n",
    "                print('Confusion Matrix:\\n')\n",
    "                print(f'{confusion_matrix(y_test, y_pred)}\\n')\n",
    "\n",
    "                print('Classification Report:\\n')\n",
    "                print(f'{classification_report(y_test, y_pred)}\\n')\n",
    "                print('_____________________________________________________________________')\n",
    "                print('\\n')\n",
    "            \n",
    "    print(f'Evaluation metrics written to \\\"{file_path}\\\"')\n",
    "\n",
    "evaluate_models(models_list, X_test, y_test, 'results/evaluation_metrics.txt', print_console = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d42df1bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T23:14:13.467366Z",
     "start_time": "2023-02-28T22:37:08.017316Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_evaluation_metrics(models_list, X_test, y_test):\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    for model in models_list:\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "#         roc_auc = roc_auc_score(y_test, y_score)\n",
    "        \n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "#         roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "    # Create a bar chart of the evaluation metrics for each model\n",
    "    x_pos = np.arange(len(models_list))\n",
    "    width = 0.15\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    \n",
    "    ax.bar(x_pos - 2*width, accuracy_scores, width, label='Accuracy')\n",
    "    ax.bar(x_pos - width, precision_scores, width, label='Precision')\n",
    "    ax.bar(x_pos, recall_scores, width, label='Recall')\n",
    "    ax.bar(x_pos + width, f1_scores, width, label='F1 Score')\n",
    "#     ax.bar(x_pos + 2*width, roc_auc_scores, width, label='ROC AUC')\n",
    "    \n",
    "    # Add the metric values above each bar\n",
    "    for i in range(len(models_list)):\n",
    "        ax.text(x_pos[i] - 2*width, accuracy_scores[i] + 0.01, f'{accuracy_scores[i]:.2f}', rotation=0, ha='center', va='bottom')\n",
    "        ax.text(x_pos[i] - width, precision_scores[i] + 0.01, f'{precision_scores[i]:.2f}', rotation=0, ha='center', va='bottom')\n",
    "        ax.text(x_pos[i], recall_scores[i] + 0.01, f'{recall_scores[i]:.2f}', rotation=0, ha='center', va='bottom')\n",
    "        ax.text(x_pos[i] + width, f1_scores[i] + 0.01, f'{f1_scores[i]:.2f}', rotation=0, ha='center', va='bottom')\n",
    "#         ax.text(x_pos[i] + 2*width, roc_auc_scores[i] + 0.01, f'{roc_auc_scores[i]:.3f}', rotation=0, ha='center', va='bottom')\n",
    "        \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([model.__class__.__name__ for model in models_list], rotation=45, ha='right')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Evaluation Metrics for Models')\n",
    "    ax.legend()   \n",
    "    # Save the figure to the 'results' folder\n",
    "    plt.savefig('results/performance_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_evaluation_metrics(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9a432012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T23:15:54.154032Z",
     "start_time": "2023-02-28T23:15:54.134840Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curves(models_list, X_test, y_test):\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    for model in models_list:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label='{} (AUC = {:.3f})'.format(model.__class__.__name__, auc_score))\n",
    "    \n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    # Save the figure to the 'results' folder\n",
    "    plt.savefig('results/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curves(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3abc44e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T23:16:07.209804Z",
     "start_time": "2023-02-28T23:16:07.190727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Random Forest: 0.9144\n",
      "KNN: 0.8759\n",
      "Decision Tree: 0.8627\n",
      "Neural Network: 0.8588\n",
      "Gradient Boosting: 0.8650\n",
      "Logistic Regression: 0.6729\n",
      "AdaBoost: 0.8447\n",
      "Extra Trees: 0.9100\n",
      "\n",
      "Precision:\n",
      "Random Forest: 0.9140\n",
      "KNN: 0.8751\n",
      "Decision Tree: 0.8633\n",
      "Neural Network: 0.8588\n",
      "Gradient Boosting: 0.8743\n",
      "Logistic Regression: 0.6435\n",
      "AdaBoost: 0.8532\n",
      "Extra Trees: 0.9094\n",
      "\n",
      "Recall:\n",
      "Random Forest: 0.9144\n",
      "KNN: 0.8759\n",
      "Decision Tree: 0.8627\n",
      "Neural Network: 0.8588\n",
      "Gradient Boosting: 0.8650\n",
      "Logistic Regression: 0.6729\n",
      "AdaBoost: 0.8447\n",
      "Extra Trees: 0.9100\n",
      "\n",
      "F1 Score:\n",
      "Random Forest: 0.9135\n",
      "KNN: 0.8733\n",
      "Decision Tree: 0.8630\n",
      "Neural Network: 0.8584\n",
      "Gradient Boosting: 0.8672\n",
      "Logistic Regression: 0.6422\n",
      "AdaBoost: 0.8470\n",
      "Extra Trees: 0.9092\n",
      "\n",
      "ROC AUC:\n",
      "Random Forest: 0.8932\n",
      "KNN: 0.8422\n",
      "Decision Tree: 0.8467\n",
      "Neural Network: 0.8380\n",
      "Gradient Boosting: 0.8675\n",
      "Logistic Regression: 0.5741\n",
      "AdaBoost: 0.8426\n",
      "Extra Trees: 0.8897\n",
      "\n",
      "The results have been saved to model_evaluation_results.txt\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrices(models_list, X_test, y_test):\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "    plt.suptitle('Confusion Matrices', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i, model in enumerate(models_list):\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        ax = plt.subplot(2, 4, i+1)\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', annot_kws={\"size\": 16})\n",
    "        ax.set_title('{0}\\n'.format(model.__class__.__name__),\n",
    "                                                       fontdict={'fontsize': 12})\n",
    "\n",
    "        ax.set_xlabel('Predicted label')\n",
    "        ax.set_ylabel('True label')\n",
    "    # Save the figure to the 'results' folder\n",
    "    plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrices(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e84ba",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Plots the comparison charts for Accuracy, Precision, Recall, F1 Score and ROC-AUC and confusion matrix of the four classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42acce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(models_list, X_test, y_test):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.step([0, 1], [1, 0], linestyle='--', color='gray', alpha=0.5, where='post')\n",
    "    for model in models_list:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        aps = average_precision_score(y_test, y_pred_proba)\n",
    "        plt.step(recall, precision, alpha=0.7, label=f'{model.__class__.__name__} (AP = {aps:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    # Save the figure to the 'results' folder\n",
    "    plt.savefig('results/precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curve(models_list, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot learning curves\n",
    "\n",
    "\n",
    "def plot_learning_curves(models, X, y):\n",
    "    # Compute the number of models\n",
    "    n_models = len(models)\n",
    "    \n",
    "    # Create a figure with n_models rows and one column\n",
    "    fig, axes = plt.subplots(n_models, 1, figsize=(8, 6*n_models))\n",
    "    \n",
    "    # Loop through each model and plot its learning curve.\n",
    "    for i, model in enumerate(models):\n",
    "        # Compute the learning curve for the current model.\n",
    "        train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, n_jobs=-1, random_state=42)\n",
    "        \n",
    "        # Compute the mean and standard deviation of the training scores and test scores.\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        \n",
    "        # Plot the learning curve for the current model.\n",
    "        ax = axes[i]\n",
    "        ax.set_title(f\"Learning Curve ({type(model).__name__})\")\n",
    "        ax.set_xlabel(\"Training Examples\")\n",
    "        ax.set_ylabel(\"Score\")\n",
    "        ax.set_ylim(0.0, 1.1)\n",
    "        ax.grid()\n",
    "        \n",
    "        ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "        ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "        \n",
    "        ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "        ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "        \n",
    "        ax.legend(loc=\"best\")\n",
    "    \n",
    "    # Save the figure to the 'results' folder\n",
    "    plt.savefig('results/learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your models list and data\n",
    "plot_learning_curves(models_list, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
